"""
"""
check_bounds(X::Number, LB::Number, UB::Number) = X < LB || X > UB ? throw(DomainError) : nothing
check_bounds(X::Number, LB::Number) = X < LB ? throw(DomainError) : nothing




"""
    ecm(estim_settings::EstimSettings)

Estimate an elastic-net VAR(p) using the ECM algorithm in Pellegrino (2019).

# Arguments
- `estim_settings`: settings used for the estimation

# References
Pellegrino (2019)
"""
function ecm(estim_settings::EstimSettings)

    # Check inputs
    check_bounds(estim_settings.p, 1);
    check_bounds(estim_settings.Î», 0);
    check_bounds(estim_settings.Î±, 0, 1);
    check_bounds(estim_settings.Î², 1);
    check_bounds(estim_settings.max_iter, 3);
    check_bounds(estim_settings.prerun, estim_settings.max_iter);
    check_bounds(estim_settings.n, 2); # It supports only multivariate models (for now ...)


    #=
    -----------------------------------------------------------------------------------------------------------------------------------------------------
    ECM initialisation
    -----------------------------------------------------------------------------------------------------------------------------------------------------
    =#

    # Interpolated data (used for the initialisation only)
    Y_init = copy(Y);
    for i=1:n
        Y_init[i, ismissing.(Y_init[i, :])] .= mean_skipmissing(Y_init[i, :]);
    end
    Y_init = Y_init |> Array{Float64};

    # Initialise using the coordinate descent algorithm
    if verb == true
        println("ecm > initialisation");
    end
    Î¨Ì‚_init, Î£Ì‚_init = coordinate_descent(Y_init, p, Î», Î±, Î², tol=tol, max_iter=max_iter, verb=false);


    #=
    -----------------------------------------------------------------------------------------------------------------------------------------------------
    Memory pre-allocation
    -----------------------------------------------------------------------------------------------------------------------------------------------------
    =#

    #=
    The state vector includes additional n terms with respect to the standard VAR companion form representation.
    This is to estimate the lag-one covariance smoother as in Watson and Engle (1983).
    =#

    # State-space parameters
    BÌ‚ = [Matrix{Float64}(I, n, n) zeros(n, np)];
    RÌ‚ = Matrix{Float64}(I, n, n).*Îµ;
    CÌ‚, VÌ‚ = ext_companion_form(Î¨Ì‚_init, Î£Ì‚_init);

    # Initial conditions
    ğ”›0Ì‚ = zeros(np+n);
    P0Ì‚ = reshape((I-kron(CÌ‚, CÌ‚))\VÌ‚[:], np+n, np+n);
    P0Ì‚ = sym(P0Ì‚);

    # Initialise additional variables
    Î¨Ì‚ = CÌ‚[1:n, 1:np];
    Î£Ì‚ = VÌ‚[1:n, 1:n];
    Î¦Ì‚áµ = 1 ./ (abs.(Î¨Ì‚).+Îµ);

    # ECM controls
    pen_loglik_old = -Inf;
    pen_loglik_new = -Inf;


    #=
    -----------------------------------------------------------------------------------------------------------------------------------------------------
    ECM algorithm
    -----------------------------------------------------------------------------------------------------------------------------------------------------
    =#

    # Run ECM
    for iter=1:max_iter

        # Run Kalman filter and smoother
        ğ”›sÌ‚, PsÌ‚, _, ğ”›s_0Ì‚, Ps_0Ì‚, _, _, _, loglik = kalman(Y, BÌ‚, RÌ‚, CÌ‚, VÌ‚, ğ”›0Ì‚, P0Ì‚; loglik_flag=true);

        if iter > prerun

            # New penalised loglikelihood
            pen_loglik_new = loglik - 0.5*tr(sym_inv(Î£Ì‚)*((1-Î±).*sym(Î¨Ì‚*Î“*Î¨Ì‚') + Î±.*sym((Î¨Ì‚.*sqrt.(Î¦Ì‚áµ))*Î“*(Î¨Ì‚.*sqrt.(Î¦Ì‚áµ))')));
            if verb == true
                println("ecm > iter=$(iter-prerun), penalised loglik=$(round(pen_loglik_new, digits=5))");
            end

            # Stop when the ECM algorithm converges
            if iter > prerun+1
                if (pen_loglik_new-pen_loglik_old)./(abs(pen_loglik_old)+Îµ) <= tol
                    if verb == true
                        println("ecm > converged!");
                        println("");
                    end
                    break;
                end
            end

            # Store current run information
            pen_loglik_old = copy(pen_loglik_new);

        elseif verb == true
            println("ecm > prerun $iter (out of $prerun)");
        end

        # Initial conditions
        ğ”›0Ì‚ = copy(ğ”›s_0Ì‚);
        P0Ì‚ = copy(Ps_0Ì‚);

        # ECM statistics
        EÌ‚ = zeros(n, n);
        FÌ‚ = zeros(n, np);
        GÌ‚ = zeros(np, np);

        for t=1:T
            EÌ‚ += ğ”›sÌ‚[1:n,t]*ğ”›sÌ‚[1:n,t]' + PsÌ‚[1:n,1:n,t];

            if t == 1
                FÌ‚ += ğ”›sÌ‚[1:n,t]*ğ”›0Ì‚[1:np]' + PsÌ‚[1:n,n+1:end,t];
                GÌ‚ += ğ”›0Ì‚[1:np]*ğ”›0Ì‚[1:np]' + P0Ì‚[1:np,1:np];

            else
                FÌ‚ += ğ”›sÌ‚[1:n,t]*ğ”›sÌ‚[1:np,t-1]' + PsÌ‚[1:n,n+1:end,t];
                GÌ‚ += ğ”›sÌ‚[1:np,t-1]*ğ”›sÌ‚[1:np,t-1]' + PsÌ‚[1:np,1:np,t-1];
            end
        end

        # VAR(p) coefficients
        Î¦Ì‚áµ = 1 ./ (abs.(Î¨Ì‚).+Îµ);
        for i=1:n
            CÌ‚[i, 1:np] = sym_inv(GÌ‚ + Î“.*((1-Î±)*I + Î±.*Diagonal(Î¦Ì‚áµ[i, :])))*FÌ‚[i,:];
        end

        # Update Î¨Ì‚
        Î¨Ì‚ = CÌ‚[1:n, 1:np];

        # Covariance matrix of the VAR(p) residuals
        VÌ‚[1:n, 1:n] = sym(EÌ‚-FÌ‚*Î¨Ì‚'-Î¨Ì‚*FÌ‚'+Î¨Ì‚*GÌ‚*Î¨Ì‚') + (1-Î±).*sym(Î¨Ì‚*Î“*Î¨Ì‚') + Î±.*sym((Î¨Ì‚.*sqrt.(Î¦Ì‚áµ))*Î“*(Î¨Ì‚.*sqrt.(Î¦Ì‚áµ))');
        VÌ‚[1:n, 1:n] *= 1/T;

        # Update Î£Ì‚
        Î£Ì‚ = VÌ‚[1:n, 1:n];
    end

    # The output excludes the additional n terms required to estimate the lag-one covariance smoother as described above.
    return BÌ‚[:,1:np], RÌ‚, CÌ‚[1:np,1:np], VÌ‚[1:np,1:np], ğ”›0Ì‚[1:np], P0Ì‚[1:np,1:np], Î¨Ì‚_init, Î£Ì‚_init;
end
